---
title: "Adv. ML. Lab 2"
author: "Simon Jorstedt"
date: "`r Sys.Date()`"
output: pdf_document
---

# Problem 1
In this lab we will construct and simulate a Hidden Markov Model where we imagine an agent walking along a cycle of states such that the agent in each time step will stay or move on to the next step with equal probabilities. There are ten states, so the agent can move from state 1 to 2, 2 to 3, etc, and from state 10 to 1. The hidden states in the model will represent the true position of the agent, while the emissions will be randomly selected from the set $\{i-2, i-1, i, i+1, i+2\}$ when the agent is in state $i$. For the simulations, we let the agent start in a uniformly randomly selected state. Below we create the programmatic setup such as the transition probability matrix, the emission probability matrix and the HMM. The states are the integers $1, \cdots, 10$, and in this case so are the emission symbols.

```{r Setup}
# This chunk is for like, loading packages, and like doing other kinds of setup
# like creating the starting probabilities and the transition probability matrix.

library(HMM)

startProbs <- rep(0.1, 10)

transProbs <- matrix(c(c(0.5, 0.5,  0,   0,   0,   0,   0,   0,   0,     0),
                       c(0,   0.5,  0.5, 0,   0,   0,   0,   0,   0,     0),
                       c(0,   0,    0.5, 0.5, 0,   0,   0,   0,   0,     0),
                       c(0,   0,    0,   0.5, 0.5, 0,   0,   0,   0,     0),
                       c(0,   0,    0,   0,   0.5, 0.5, 0,   0,   0,     0),
                       c(0,   0,    0,   0,   0,   0.5, 0.5, 0,   0,     0),
                       c(0,   0,    0,   0,   0,   0,   0.5, 0.5, 0,     0),
                       c(0,   0,    0,   0,   0,   0,   0,   0.5, 0.5,   0),
                       c(0,   0,    0,   0,   0,   0,   0,   0,   0.5,   0.5),
                       c(0.5, 0,    0,   0,   0,   0,   0,   0,   0,     0.5)
                       ), nrow = 10, ncol = 10, byrow = TRUE)

emissionProbs <- matrix(c(c(0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2),
                          c(0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2),
                          c(0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0),
                          c(0.0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0),
                          c(0.0, 0.0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0),
                          c(0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0),
                          c(0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0),
                          c(0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.2, 0.2),
                          c(0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.2),
                          c(0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2)
                          ), nrow = 10, ncol = 10, byrow = TRUE)

# Initialise a HMM model
HMM_1 <- initHMM(States = 1:10,
                 Symbols = 1:10,
                 startProbs = startProbs,
                 transProbs = transProbs,
                 emissionProbs = emissionProbs)
```

# Problem 2
Now we shall simulate the HMM that we initiated previously. This comes down to just running the `simHMM` function.

```{r Simulations}
set.seed(322347)
HMM_sim1 <- simHMM(HMM_1, length = 100)
HMM_sim2 <- simHMM(HMM_1, length = 100)
HMM_sim3 <- simHMM(HMM_1, length = 100)
HMM_sim4 <- simHMM(HMM_1, length = 100)
```

# Problem 3
Now we shall use our emission observations above to compute the smoothed and filtered probability distributions using `HMM::backward` and `HMM:forward` respectively. We will also compute the most probable path using the Viterbi algorithm. In Figure 1 below we also visualize the true path (black), the emitted/observed path (blue), and the most probable path (red). We create two custom functions to calculate the most probable "filtered" and "smoothed" states.

```{r}
likeliest_states <- function(HMM, Simulation){
  alphas <- exp(forward(HMM, observation = Simulation$observation))
  betas <- exp(backward(HMM, observation = Simulation$observation))
  
  filtered_probabilities <- prop.table(alphas, margin=2)
  smoothed_probabilities <- prop.table(alphas*betas, margin=2)
  
  filtered_states <- apply(filtered_probabilities, FUN=which.max, MARGIN=2)
  smoothed_states <- apply(smoothed_probabilities, FUN=which.max, MARGIN=2)
  
  return(list(filtered_states, smoothed_states))
}
```

```{r}
# Find the most likely state for each time step, from the filtered and smoothed
# probabilities.
likely_states_1 <- likeliest_states(HMM_1, HMM_sim1)

filtered_states_1 <- likely_states_1[[2]]
smoothed_states_1 <- likely_states_1[[1]]

plot(HMM_sim1$states, type="l", xlab="Time index", ylab="State",
     main="Fig 2: Most probable states from filtered (red) and smoothed (blue)\n probabilities")
points(filtered_states_1, type="l", col="red")
points(smoothed_states_1, type="l", col="blue")
```

```{r}
# Visualization of the most probable path,
# calculated using the Viterbi algorithm

viterbi_run1 <- HMM::viterbi(HMM_1, HMM_sim1$observation)
plot(HMM_sim1$states, type="l", xlab="Time index", ylab="State",
     main="Fig 2: Most probable path")
points(viterbi_run1, type="l", col="red")
```

# Problem 4 and 5
Now compute accuracy of filtered and smoothed probability distributions and of the most probable path.

```{r}
print("Simulation 1 accuracies")
mean(HMM_sim1$states == likely_states_1[[1]]) # Filtered
mean(HMM_sim1$states == likely_states_1[[2]]) # Smoothed
mean(HMM_sim1$states == viterbi_run1) # Most probable path
```


```{r}
print("Simulation 2 accuracies")
likely_states_2 <- likeliest_states(HMM_1, HMM_sim2)
mean(HMM_sim2$states == likely_states_2[[1]]) # Filtered
mean(HMM_sim2$states == likely_states_2[[2]]) # Smoothed
mean(HMM_sim2$states == viterbi(HMM_1, HMM_sim2$observation)) # Most probable path
```

```{r}
print("Simulation 3 accuracies")
likely_states_3 <- likeliest_states(HMM_1, HMM_sim3)
mean(HMM_sim3$states == likely_states_3[[1]]) # Filtered
mean(HMM_sim3$states == likely_states_3[[2]]) # Smoothed
mean(HMM_sim3$states == viterbi(HMM_1, HMM_sim3$observation)) # Most probable path
```

# Problem 6
It should in general be true that over time, more observations means the accuracy of the estimate of the robots location increases. However, let us investigate this.

```{r}
library(entropy)


alphas <- exp(forward(HMM_1, observation = HMM_sim2$observation))
#betas <- exp(backward(HMM_1, observation = HMM_sim2$observation))
filtered_probabilities <- prop.table(alphas, margin=2)

filter_entropy <- c()
for (i in 1:length(filtered_probabilities[1,])){
  filter_entropy <- c(filter_entropy, entropy.empirical(filtered_probabilities[,i]))
}

plot(filter_entropy, type="l", xlab="Time index", ylab="Entropy",
     main="Fig 3: Entropy over time")
```


# Problem 7
Now we shall compute the probabilities of the hidden states for time step 101, given the sample in one of the simulations. This can be interpreted as conditioning either on the hidden state in time step 100, or as conditioning on the observation in time step 100. In the first case, we can simply grab the transition probabilities of the row corresponding to that state, as that will give the probabilities of the next state. In the other case, we must first get the possible true hidden states corresponding to the observed state $i$ in observation 100. All those five states are equally likely We can then simply add the rows of those states in the transition probability matrix column wise. 

```{r}
observation <- HMM_sim1$observation[length(HMM_sim1$observation)]
possible_hidden_states <- seq(observation-2, observation+2)

# Compute probabilities of future state one step in the future
prop.table(colSums(transProbs[possible_hidden_states,]))
```




