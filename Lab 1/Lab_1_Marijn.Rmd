---
title: "Lab 1 Marijn"
output: pdf_document
date: "2024-09-10"
---

```{r Setup, include=FALSE}
# Install required packages
# if (!requireNamespace("BiocManager", quietly=TRUE))
# install.packages("BiocManager")
# 
# BiocManager::install("RBGL")
# BiocManager::install("Rgraphviz")
# BiocManager::install("gRain", force=TRUE)
```


```{r Libraries, include=FALSE}
library(gRain)
library(bnlearn)
library(dplyr)
library(caret)
```

# Question 1
```{r}
# Load data
data("asia")

# Create and compare graphs with HC alg
graph1 <- hc(asia, score="bde", iss=100, restart=10)
graph2 <- hc(asia, score="bde", iss=1, restart=10)

# graphviz.plot(graph1)
# graphviz.plot(graph2)
graphviz.compare(graph1, graph2)
```

The HC algorithm may find different network structures because it is not guaranteed to find a global optimum. In the comparison above, the imaginary sample size (ISS) was changed which means that one network regularizes less with the Bayesian score. This network is much bigger, with many more edges than the network with small ISS. Increasing the number of random restarts may also result in different graphs as introducing more randomness may lead to separate runs of the algorithm to find a different local optimum. 

# Question 2
```{r}
# Sample 80% of data for training
sample_ind <- sample(1:nrow(asia), 0.8 * nrow(asia))
df_train <- asia[sample_ind,]
df_test <- asia[-sample_ind,]

# Learn structure and parameters
# https://www.bnlearn.com/examples/fit/
graph <- hc(df_train, score="bde", iss=3, restart=20)
param <- bn.fit(graph, df_train, method="mle")

# Visualize and compare to true model
# graphviz.plot(graph)
print(fitted_graph)
# bn.fit.barchart(fitted_graph$S)

dag <- model2network("[A][S][T|A][L|S][B|S][D|B:E][E|T:L][X|E]")
graphviz.compare(graph, bn.fit(dag, asia))
```

```{r}
# Convert to grain
grain <- as.grain(param)

pred <- rep(0, nrow(df_test))
nodes <- names(df_test)[!names(df_test) %in% "S"]
for (i in 1:nrow(df_test)) {
  # Record evidence
  states <- df_test[i, nodes]
  
  # # https://www.rdocumentation.org/packages/gRain/versions/1.3-2/topics/grain-evidence
  evidence <- setEvidence(grain, nodes, states)
  
  # https://www.rdocumentation.org/packages/gRain/versions/1.4.1/topics/querygrain
  # pred[i] <- querygrain(grain, "S", evidence=evidence)
  # pred[i] <- names(which.max(querygrain(grain, "S", evidence=evidence)$S))
  cond_prob <- querygrain(grain, "S", evidence=evidence)$S
  
  if (runif(1) <= cond_prob["no"]) {
    pred[i] <- "no"
  }
  else {
    pred[i] <- "yes"
  }
}

# Compute confusion matrix
confusionMatrix(factor(pred), factor(df_test$S))
```

# Question 3
```{r}
pred <- rep(0, nrow(df_test))
for (i in 1:nrow(df_test)) {
  # Record evidence
  nodes <- mb(fitted_graph, "S")
  states <- df_test[i, nodes]
  
  # # https://www.rdocumentation.org/packages/gRain/versions/1.3-2/topics/grain-evidence
  evidence <- setEvidence(grain, nodes, states)
  
  # https://www.rdocumentation.org/packages/gRain/versions/1.4.1/topics/querygrain
  # pred[i] <- querygrain(grain, "S", evidence=evidence)
  # pred[i] <- names(which.max(querygrain(grain, "S", evidence=evidence)$S))
  cond_prob <- querygrain(grain, "S", evidence=evidence)$S
  
  if (runif(1) <= cond_prob["no"]) {
    pred[i] <- "no"
  }
  else {
    pred[i] <- "yes"
  }
}

confusionMatrix(factor(pred), factor(df_test$S))
```

# Question 4
```{r}
empty_graph <- empty.graph(c("A", "S", "T", "L", "B", "D", "E", "X"))

```